/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty.py --feature_set bert-4 --emo_dim_set valence --epochs 1 --refresh --n_seeds 1 --seed 314 --attn --rnn_bi --loss ccc --uncertainty_approach monte_carlo_dropout --attn_dr .5 --out_dr .5 --rnn_n_layers 2 --rnn_dr .5 --measure_uncertainty_globally
Constructing dataset and data loader ...
Constructing data from scratch ...
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.6726, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -1.0, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.7353, max 0.80704).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.9549, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.9706, max 0.9218999999999999).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.39030000000000004, max 0.4687).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.98725, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.8137000000000001, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 9: 9
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 10: 10
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 11: 11
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 12: 12
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 13: 13
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 14: 14
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.58476, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 16: 16
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 17: 17
Samples in partitions: (3132, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
Seed 314 | Best [Val CCC]: 0.0243 [' 0.0243']| Loss: 0.9756 | PCC: 0.1523 ['0.1523'] | RMSE: 0.7830 ['0.7830']
--------------------TEST--------------------
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.5691493922224418, 'ccc': -0.010125113663723137}], rand. GsbUME: [{'mae': 0.11983224918081087, 'ccc': -0.07227027672680988}]
GpebUME: [{'mae': 0.7100403577968027, 'ccc': 0.0034788126319133124}], rand. GpebUME: [{'mae': 0.04579197011781773, 'ccc': -0.05524792744759523}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.14125696135722032, 'ccc': 0.07412719432020783}]
Calibrated on true subjectivity:
GsbUME: [{'mae': 0.09001115380085481, 'ccc': 0.0}]
GpebUME: [{'mae': 0.07761248834933629, 'ccc': 5.169502474886362e-33}]
Calibrated on prediction score:
GsbUME: [{'mae': 0.16954571088187398, 'ccc': -0.004981801171712834}]
GpebUME: [{'mae': 0.03507703898653054, 'ccc': 0.06362205631487851}]
--------------------DEVEL--------------------
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.6322766961221418, 'ccc': -0.017433723393344563}], rand. GsbUME: [{'mae': 0.11671902838124139, 'ccc': -0.033579286180871686}]
GpebUME: [{'mae': 0.7332126274400674, 'ccc': 0.002054831790111141}], rand. GpebUME: [{'mae': 0.027713643263599003, 'ccc': -0.053669511251891865}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.1076429033952589, 'ccc': 0.023550424943611706}]
Calibrated on true subjectivity:
GsbUME: [{'mae': 0.08146422067226436, 'ccc': 0.0003189892410844017}]
GpebUME: [{'mae': 0.10072325270736086, 'ccc': 0.0001338113907095195}]
Calibrated on prediction score:
GsbUME: [{'mae': 0.10762562659126959, 'ccc': -0.041407268086384195}]
GpebUME: [{'mae': 0.01659058586718351, 'ccc': 0.28380873513485005}]
On Test: CCC  0.0635 | PCC  0.2745 | RMSE  0.6721
==================================================
On ground-truth labels:	Best	[Val CCC] for seed "314":	 0.0243
On ground-truth labels:		[Test CCC] for seed "314":	 0.0635
----------------------------------------------------------------------------------------------------
Delete model "/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/output/model/2021-06-01-18-50_[bert-4]_[valence]_[NOSEG]_[lstm_64_2_True]_[True_1_4]_[0.005_1024_0.5_0.5_0.5]_None_[1_314_None_None].pth".

/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty.py --feature_set bert-4 --emo_dim_set valence --epochs 100 --refresh --n_seeds 2 --seed 314 --attn --rnn_bi --loss ccc --uncertainty_approach monte_carlo_dropout --attn_dr .5 --out_dr .5 --rnn_n_layers 2 --rnn_dr .5 --measure_uncertainty_globally
Constructing dataset and data loader ...
Constructing data from scratch ...
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.6726, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -1.0, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.7353, max 0.80704).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.9549, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.9706, max 0.9218999999999999).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.39030000000000004, max 0.4687).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.98725, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.8137000000000001, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 9: 9
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 10: 10
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 11: 11
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 12: 12
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 13: 13
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 14: 14
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.58476, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 16: 16
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 17: 17
Samples in partitions: (3132, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 314 | Best [Val CCC]: 0.4312 [' 0.4312']| Loss: 0.6175 | PCC: 0.4429 ['0.4429'] | RMSE: 0.1844 ['0.1844']
--------------------TEST--------------------
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.7269551721269141, 'ccc': 0.0012466710604650464}], rand. GsbUME: [{'mae': 0.10468907547890031, 'ccc': 0.1780810321204633}]
GpebUME: [{'mae': 0.4064275239375772, 'ccc': 0.017892050362563056}], rand. GpebUME: [{'mae': 0.21832365521215014, 'ccc': -0.0815907468180701}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.3222465414159795, 'ccc': 0.05046001589056807}]
Calibrated on true subjectivity:
GsbUME: [{'mae': 0.0905646368362161, 'ccc': -0.0031304857525244595}]
GpebUME: [{'mae': 0.38467317653771615, 'ccc': 0.010695424110163294}]
Calibrated on prediction score:
GsbUME: [{'mae': 0.20410276182685805, 'ccc': 0.03449930163014649}]
GpebUME: [{'mae': 0.15600385753303223, 'ccc': 0.1974440514163025}]
--------------------DEVEL--------------------
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.7894962094377019, 'ccc': 0.0008503776746688375}], rand. GsbUME: [{'mae': 0.11218909584049908, 'ccc': -0.1644635468578265}]
GpebUME: [{'mae': 0.5371626541160643, 'ccc': 0.006837536174114451}], rand. GpebUME: [{'mae': 0.2023121104973467, 'ccc': -0.08316137564775293}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.2766352871717018, 'ccc': 0.07792845395761393}]
Calibrated on true subjectivity:
GsbUME: [{'mae': 0.08207532666034142, 'ccc': 0.0469387790550328}]
GpebUME: [{'mae': 0.2707164014628288, 'ccc': 0.02002580333074063}]
Calibrated on prediction score:
GsbUME: [{'mae': 0.24938969735674862, 'ccc': 0.02792180927187835}]
GpebUME: [{'mae': 0.15038454376155255, 'ccc': 0.3580820501420597}]
On Test: CCC  0.6063 | PCC  0.6208 | RMSE  0.1608
==================================================
Training model... [seed 315]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 315 | Best [Val CCC]: 0.4431 [' 0.4431']| Loss: 0.6209 | PCC: 0.4516 ['0.4516'] | RMSE: 0.1921 ['0.1921']
--------------------TEST--------------------
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.7181855645950763, 'ccc': 0.00028239295075997326}], rand. GsbUME: [{'mae': 0.10750185600140305, 'ccc': -0.03450759839765887}]
GpebUME: [{'mae': 0.38411329543059836, 'ccc': 0.01921672129788702}], rand. GpebUME: [{'mae': 0.1672365062249197, 'ccc': 0.004372477537661739}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.3371398801730924, 'ccc': 0.06423628714959025}]
Calibrated on true subjectivity:
GsbUME: [{'mae': 0.09496242557765974, 'ccc': 0.00578448847693836}]
GpebUME: [{'mae': 0.40030147214734807, 'ccc': 0.0259481548745451}]
Calibrated on prediction score:
GsbUME: [{'mae': 0.2278641078882473, 'ccc': 0.01523778602622202}]
GpebUME: [{'mae': 0.1544052136016899, 'ccc': 0.29454629931095627}]
--------------------DEVEL--------------------
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.7838057031945157, 'ccc': 0.0006056112308988732}], rand. GsbUME: [{'mae': 0.11860724744500663, 'ccc': 0.07849164895003546}]
GpebUME: [{'mae': 0.5025299620653854, 'ccc': 0.0055844076867927256}], rand. GpebUME: [{'mae': 0.20131752384559767, 'ccc': -0.08990551495554523}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.29684703051832934, 'ccc': 0.0795348737571323}]
Calibrated on true subjectivity:
GsbUME: [{'mae': 0.08041420049011154, 'ccc': 0.11464873505866699}]
GpebUME: [{'mae': 0.29322682639825887, 'ccc': 0.026811481380685457}]
Calibrated on prediction score:
GsbUME: [{'mae': 0.27161643500561927, 'ccc': 0.00777691988877432}]
GpebUME: [{'mae': 0.14145172949978355, 'ccc': 0.2305270827400907}]
On Test: CCC  0.6028 | PCC  0.6147 | RMSE  0.1555
==================================================
On ground-truth labels:	Best	[Val CCC] for seed "315":	 0.4431
On ground-truth labels:		[Test CCC] for seed "315":	 0.6028
----------------------------------------------------------------------------------------------------
Delete model "/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/output/model/2021-06-01-20-44_[bert-4]_[valence]_[NOSEG]_[lstm_64_2_True]_[True_1_4]_[0.005_1024_0.5_0.5_0.5]_None_[2_315_None_None].pth".
slurmstepd: Exceeded step memory limit at some point.
slurmstepd: Exceeded job memory limit at some point.
