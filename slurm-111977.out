/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty_ensemble.py --feature_set bert-4 --emo_dim_set valence --epochs 100 --refresh --n_seeds 5 --seed 314 --attn --rnn_bi --loss ccc --uncertainty_approach ensemble_averaging --attn_dr .5 --out_dr .5 --rnn_n_layers 2 --rnn_dr .5 --measure_uncertainty_globally --global_uncertainty_window 20 --normalize_uncalibrated_global_uncertainty_measurement --load_subjectivity_from_file
Constructing dataset and data loader ...
Constructing data from scratch ...
Subjectivities deserialized from file.
Samples in partitions: (3132, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 314 | Best [Val CCC]: 0.4312 [' 0.4312']| Loss: 0.6175 | PCC: 0.4429 ['0.4429'] | RMSE: 0.1844 ['0.1844']
On Test: CCC  0.5993 | PCC  0.6123 | RMSE  0.1657
==================================================
Training model... [seed 315]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 315 | Best [Val CCC]: 0.4431 [' 0.4431']| Loss: 0.6209 | PCC: 0.4516 ['0.4516'] | RMSE: 0.1921 ['0.1921']
On Test: CCC  0.6043 | PCC  0.6123 | RMSE  0.1572
==================================================
Training model... [seed 316]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 316 | Best [Val CCC]: 0.4489 [' 0.4489']| Loss: 0.5958 | PCC: 0.4500 ['0.4500'] | RMSE: 0.1740 ['0.1740']
On Test: CCC  0.5918 | PCC  0.6051 | RMSE  0.1567
==================================================
Training model... [seed 317]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 317 | Best [Val CCC]: 0.4549 [' 0.4549']| Loss: 0.6081 | PCC: 0.4552 ['0.4552'] | RMSE: 0.1705 ['0.1705']
On Test: CCC  0.5869 | PCC  0.5916 | RMSE  0.1664
==================================================
Training model... [seed 318]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 318 | Best [Val CCC]: 0.4311 [' 0.4311']| Loss: 0.6124 | PCC: 0.4329 ['0.4329'] | RMSE: 0.1718 ['0.1718']
On Test: CCC  0.6114 | PCC  0.6155 | RMSE  0.1650
==================================================
--------------------TEST--------------------
Confirmed prediction ccc-score: 0.5464048520499647
Calibrator: isotonic_regression
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.3906945602366754, 'ccc': 0.08230650497793386, 'ence': 0.20507422390622987}], rand. GsbUME: [{'mae': 0.24179927508367152, 'ccc': 0.0031917494171640253, 'ence': 0.11804048429865087}]
GpebUME: [{'mae': 0.45905947838301947, 'ccc': 0.21480268490541513, 'ence': 0.18325537519355853}], rand. GpebUME: [{'mae': 0.2874041062815638, 'ccc': 0.01177327414365175, 'ence': 0.09178591707927063}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.5912491461295089, 'ccc': 0.04149559554724206, 'ence': 0.17515146414000302}]
var: {'subj. pred.': 0.1794707841053507, 'subj. true.': 0.047397375, 'pred. err.': 0.06865326717705741}
Cv: {'subj. pred.': -1.622093194221987, 'subj. true.': -0.43708278461388494, 'pred. err.': 3.4025631045446505}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06308363850837756, 'ccc': 0.030934631225376704, 'ence': 0.010631247077225353}]
GpebUME: [{'mae': 0.15442353385822474, 'ccc': 0.027770296354564263, 'ence': 0.06117663117440026}]
var: {'subj. pred.': 0.00012869862618638858, 'subj. true.': 0.0069582327, 'pred. err.': 0.06419404364919057}
Cv: {'subj. pred.': 0.2585632824000501, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5284859906734667}

Calibrated on prediction score:
GsbUME: [{'mae': 0.07544266462854991, 'ccc': 0.11053695098013447, 'ence': 0.09366554992040484}]
GpebUME: [{'mae': 0.14906807039716116, 'ccc': 0.16006304396873422, 'ence': 0.014422279811252886}]
var: {'subj. pred.': 0.004389501612339774, 'subj. true.': 0.0069582327, 'pred. err.': 0.06419404364919057}
Cv: {'subj. pred.': 0.8941039965313904, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5284859906734667}

Calibrator: std_scaling
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.3906945602366754, 'ccc': 0.08230650497793386, 'ence': 0.20507422390622987}], rand. GsbUME: [{'mae': 0.24189080179722597, 'ccc': 0.0012463239289108683, 'ence': 0.08791950372314611}]
GpebUME: [{'mae': 0.45905947838301947, 'ccc': 0.21480268490541513, 'ence': 0.18325537519355853}], rand. GpebUME: [{'mae': 0.2851473684504057, 'ccc': -0.024394337110244413, 'ence': 0.16465007687216368}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.5912491461295089, 'ccc': 0.04149559554724206, 'ence': 0.17515146414000302}]
var: {'subj. pred.': 0.1794707841053507, 'subj. true.': 0.047397375, 'pred. err.': 0.06865326717705741}
Cv: {'subj. pred.': -1.622093194221987, 'subj. true.': -0.43708278461388494, 'pred. err.': 3.4025631045446505}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06850805038247713, 'ccc': 5.388703262009907e-12, 'ence': 0.03241080312838398}]
GpebUME: [{'mae': 0.15831097557348922, 'ccc': 6.52903474725539e-12, 'ence': 0.050249856745949}]
var: {'subj. pred.': 7.437260707423423e-24, 'subj. true.': 0.0069582327, 'pred. err.': 0.06419404364919057}
Cv: {'subj. pred.': 0.7966619271995546, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5284859906734667}

Calibrated on prediction score:
GsbUME: [{'mae': 0.06850805038247713, 'ccc': 5.388703262009907e-12, 'ence': 0.03241080312838398}]
GpebUME: [{'mae': 0.15831097557348922, 'ccc': 6.52903474725539e-12, 'ence': 0.050249856745949}]
var: {'subj. pred.': 7.437260707423423e-24, 'subj. true.': 0.0069582327, 'pred. err.': 0.06419404364919057}
Cv: {'subj. pred.': 0.7966619271995546, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5284859906734667}

--------------------DEVEL--------------------
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:210: RuntimeWarning: divide by zero encountered in log
  regularization = (len(val_uncalibrated) / 2) * np.log(s)
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: divide by zero encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: invalid value encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:210: RuntimeWarning: divide by zero encountered in log
  regularization = (len(val_uncalibrated) / 2) * np.log(s)
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: divide by zero encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: invalid value encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
Confirmed prediction ccc-score: 0.4219437780138436
Calibrator: isotonic_regression
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.37949690448417206, 'ccc': 0.04881273579637505, 'ence': 0.20567840318061945}], rand. GsbUME: [{'mae': 0.21233716215365392, 'ccc': -0.005639334559418879, 'ence': 0.07766288261398917}]
GpebUME: [{'mae': 0.4649126017335843, 'ccc': 0.12319419423636575, 'ence': 0.19011436197139284}], rand. GpebUME: [{'mae': 0.2354146337107019, 'ccc': -0.0026795277899507217, 'ence': 0.15579323365839148}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.6616414198807734, 'ccc': 0.02412760151443899, 'ence': 0.1982141295021914}]
var: {'subj. pred.': 0.1468639447641188, 'subj. true.': 0.039491754, 'pred. err.': 0.04931823313275906}
Cv: {'subj. pred.': -1.2585953085379744, 'subj. true.': -0.33696727768754087, 'pred. err.': 3.71229347511006}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06097125116864307, 'ccc': 0.024473703343503555, 'ence': 8.651271879735187e-09}]
GpebUME: [{'mae': 0.12562050722737828, 'ccc': 0.021383878762611976, 'ence': 0.03005505201024317}]
var: {'subj. pred.': 9.570743627032374e-05, 'subj. true.': 0.007725539, 'pred. err.': 0.046994636378291085}
Cv: {'subj. pred.': 0.23364869267447957, 'subj. true.': 2.099205399517044, 'pred. err.': 3.539849567419639}

Calibrated on prediction score:
GsbUME: [{'mae': 0.07321610496687053, 'ccc': 0.07822599112607939, 'ence': 0.076625904023577}]
GpebUME: [{'mae': 0.1251893519838141, 'ccc': 0.12705573876881757, 'ence': 0.0}]
var: {'subj. pred.': 0.0031879956957665784, 'subj. true.': 0.007725539, 'pred. err.': 0.046994636378291085}
Cv: {'subj. pred.': 0.921975801681741, 'subj. true.': 2.099205399517044, 'pred. err.': 3.539849567419639}

Calibrator: std_scaling
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.37949690448417206, 'ccc': 0.04881273579637505, 'ence': 0.20567840318061945}], rand. GsbUME: [{'mae': 0.21207273792978754, 'ccc': 0.014828770731891778, 'ence': 0.08386067622717824}]
GpebUME: [{'mae': 0.4649126017335843, 'ccc': 0.12319419423636575, 'ence': 0.19011436197139284}], rand. GpebUME: [{'mae': 0.23513725975868172, 'ccc': -0.0170471421090296, 'ence': 0.1513613352074943}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.6616414198807734, 'ccc': 0.02412760151443899, 'ence': 0.1982141295021914}]
var: {'subj. pred.': 0.1468639447641188, 'subj. true.': 0.039491754, 'pred. err.': 0.04931823313275906}
Cv: {'subj. pred.': -1.2585953085379744, 'subj. true.': -0.33696727768754087, 'pred. err.': 3.71229347511006}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.052548720943235566, 'ccc': 4.011942296455959e-12, 'ence': 0.016468645287695146}]
GpebUME: [{'mae': 0.12094681646820844, 'ccc': 5.12805155781768e-12, 'ence': 0.03662818174468364}]
var: {'subj. pred.': 6.356907587911451e-24, 'subj. true.': 0.007725539, 'pred. err.': 0.046994636378291085}
Cv: {'subj. pred.': 0.8803199317890611, 'subj. true.': 2.099205399517044, 'pred. err.': 3.539849567419639}

Calibrated on prediction score:
GsbUME: [{'mae': 0.052548720943235566, 'ccc': 4.011942296455959e-12, 'ence': 0.016468645287695146}]
GpebUME: [{'mae': 0.12094681646820844, 'ccc': 5.12805155781768e-12, 'ence': 0.03662818174468364}]
var: {'subj. pred.': 6.356907587911451e-24, 'subj. true.': 0.007725539, 'pred. err.': 0.046994636378291085}
Cv: {'subj. pred.': 0.8803199317890611, 'subj. true.': 2.099205399517044, 'pred. err.': 3.539849567419639}

On ground-truth labels:	Best	[Val CCC] for seed "317":	 0.4549
On ground-truth labels:		[Test CCC] for seed "317":	 0.5869
----------------------------------------------------------------------------------------------------
Delete model "/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/output/model/2021-06-10-21-27_[bert-4]_[valence]_[NOSEG]_[lstm_64_2_True]_[True_1_4]_[0.005_1024_0.5_0.5_0.5]_None_[5_317_None_None].pth".
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty.py --feature_set bert-4 --emo_dim_set valence --epochs 100 --refresh --n_seeds 1 --seed 314 --attn --rnn_bi --loss ccc --uncertainty_approach monte_carlo_dropout --attn_dr .5 --out_dr .5 --rnn_n_layers 2 --rnn_dr .5 --measure_uncertainty_globally --global_uncertainty_window 20 --normalize_uncalibrated_global_uncertainty_measurement --load_subjectivity_from_file
Constructing dataset and data loader ...
Constructing data from scratch ...
Subjectivities deserialized from file.
Samples in partitions: (3132, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 314 | Best [Val CCC]: 0.4312 [' 0.4312']| Loss: 0.6175 | PCC: 0.4429 ['0.4429'] | RMSE: 0.1844 ['0.1844']
--------------------TEST--------------------
Confirmed prediction ccc-score: 0.5162410660849408
Calibrator: isotonic_regression
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.48436040690070503, 'ccc': 0.0642835213809465, 'ence': 0.4480667757434011}], rand. GsbUME: [{'mae': 0.23664425869663075, 'ccc': -0.004270089580032273, 'ence': 0.14519080399600817}]
GpebUME: [{'mae': 0.44511952424160695, 'ccc': 0.243297296485713, 'ence': 0.23100603556000124}], rand. GpebUME: [{'mae': 0.2729326265537677, 'ccc': 0.02619503582005257, 'ence': 0.15928766494072047}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.5825972912294408, 'ccc': 0.03967840773167727, 'ence': 0.16700735054329321}]
var: {'subj. pred.': 0.2479851687859804, 'subj. true.': 0.047397375, 'pred. err.': 0.06165216492186078}
Cv: {'subj. pred.': -3.5624807324963226, 'subj. true.': -0.43708278461388494, 'pred. err.': 3.6404589561375853}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06306008078128575, 'ccc': 0.029923356920081672, 'ence': 0.07457989615527401}]
GpebUME: [{'mae': 0.1457931061147051, 'ccc': 0.029412968532596808, 'ence': 0.01677069578119865}]
var: {'subj. pred.': 0.00013692835037710006, 'subj. true.': 0.0069582327, 'pred. err.': 0.05663518393882555}
Cv: {'subj. pred.': 0.27155454662622314, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5978798395919833}

Calibrated on prediction score:
GsbUME: [{'mae': 0.07268077086679275, 'ccc': 0.1177570316208436, 'ence': 0.20110679887291627}]
GpebUME: [{'mae': 0.1381878640316454, 'ccc': 0.17346681296462949, 'ence': 0.018240775076238645}]
var: {'subj. pred.': 0.004308918595434236, 'subj. true.': 0.0069582327, 'pred. err.': 0.05663518393882555}
Cv: {'subj. pred.': 1.056167982366473, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5978798395919833}

Calibrator: std_scaling
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.48436040690070503, 'ccc': 0.0642835213809465, 'ence': 0.4480667757434011}], rand. GsbUME: [{'mae': 0.23627223687271212, 'ccc': -0.011038584188513584, 'ence': 0.12784371757110435}]
GpebUME: [{'mae': 0.44511952424160695, 'ccc': 0.243297296485713, 'ence': 0.23100603556000124}], rand. GpebUME: [{'mae': 0.2714946071165748, 'ccc': 0.02443981006289881, 'ence': 0.2393782021478402}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.5825972912294408, 'ccc': 0.03967840773167727, 'ence': 0.16700735054329321}]
var: {'subj. pred.': 0.2479851687859804, 'subj. true.': 0.047397375, 'pred. err.': 0.06165216492186078}
Cv: {'subj. pred.': -3.5624807324963226, 'subj. true.': -0.43708278461388494, 'pred. err.': 3.6404589561375853}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06850805038221118, 'ccc': 6.416325803000253e-12, 'ence': 0.13852006016309124}]
GpebUME: [{'mae': 0.14856174528693253, 'ccc': 8.294097748315375e-12, 'ence': 0.04846935292949504}]
var: {'subj. pred.': 1.0652224668838325e-23, 'subj. true.': 0.0069582327, 'pred. err.': 0.05663518393882555}
Cv: {'subj. pred.': 0.8295288060378271, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5978798395919833}

Calibrated on prediction score:
GsbUME: [{'mae': 0.06850805038221118, 'ccc': 6.416325803000253e-12, 'ence': 0.13852006016309124}]
GpebUME: [{'mae': 0.14856174528693253, 'ccc': 8.294097748315375e-12, 'ence': 0.04846935292949504}]
var: {'subj. pred.': 1.0652224668838325e-23, 'subj. true.': 0.0069582327, 'pred. err.': 0.05663518393882555}
Cv: {'subj. pred.': 0.8295288060378271, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5978798395919833}

--------------------DEVEL--------------------
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:210: RuntimeWarning: divide by zero encountered in log
  regularization = (len(val_uncalibrated) / 2) * np.log(s)
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: divide by zero encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: invalid value encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
Confirmed prediction ccc-score: 0.38115349610422505
Calibrator: isotonic_regression
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.48938182664572644, 'ccc': 0.040312065113207535, 'ence': 0.24978766555829698}], rand. GsbUME: [{'mae': 0.21545135692897738, 'ccc': 0.0009983756158085935, 'ence': 0.09018747751861116}]
GpebUME: [{'mae': 0.45529671118260756, 'ccc': 0.17298149156373852, 'ence': 0.23072791358506825}], rand. GpebUME: [{'mae': 0.2290781513321173, 'ccc': 4.9913030431670714e-05, 'ence': 0.13160101972489235}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.6335890324257817, 'ccc': 0.024290405044816468, 'ence': 0.19665155823721514}]
var: {'subj. pred.': 0.23729128908937616, 'subj. true.': 0.039491754, 'pred. err.': 0.04581020822674174}
Cv: {'subj. pred.': -2.58906574394734, 'subj. true.': -0.33696727768754087, 'pred. err.': 6.896185865917026}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06100459001657005, 'ccc': 0.019201218467841334, 'ence': 0.018561221074425874}]
GpebUME: [{'mae': 0.1181117869848823, 'ccc': 0.028136927607756674, 'ence': 0.060318397364931074}]
var: {'subj. pred.': 0.00010813984879096062, 'subj. true.': 0.007725539, 'pred. err.': 0.041460142893771104}
Cv: {'subj. pred.': 0.24933176346167502, 'subj. true.': 2.099205399517044, 'pred. err.': 3.719199904127456}

Calibrated on prediction score:
GsbUME: [{'mae': 0.07014862046996163, 'ccc': 0.08699427357237637, 'ence': 0.05599182619063236}]
GpebUME: [{'mae': 0.11456473353907343, 'ccc': 0.16317857334322686, 'ence': 0.0023304172265062634}]
var: {'subj. pred.': 0.0037908968736417477, 'subj. true.': 0.007725539, 'pred. err.': 0.041460142893771104}
Cv: {'subj. pred.': 1.1631719403188578, 'subj. true.': 2.099205399517044, 'pred. err.': 3.719199904127456}

Calibrator: std_scaling
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.48938182664572644, 'ccc': 0.040312065113207535, 'ence': 0.24978766555829698}], rand. GsbUME: [{'mae': 0.2113102212231874, 'ccc': -0.01458918321002497, 'ence': 0.12552104090789784}]
GpebUME: [{'mae': 0.45529671118260756, 'ccc': 0.17298149156373852, 'ence': 0.23072791358506825}], rand. GpebUME: [{'mae': 0.22755899322297604, 'ccc': 0.010191684874092746, 'ence': 0.1422362120016983}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.6335890324257817, 'ccc': 0.024290405044816468, 'ence': 0.19665155823721514}]
var: {'subj. pred.': 0.23729128908937616, 'subj. true.': 0.039491754, 'pred. err.': 0.04581020822674174}
Cv: {'subj. pred.': -2.58906574394734, 'subj. true.': -0.33696727768754087, 'pred. err.': 6.896185865917026}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.052548720943059915, 'ccc': 5.392914826626386e-12, 'ence': 0.015194085080670468}]
GpebUME: [{'mae': 0.1128476568501888, 'ccc': 8.022168590026318e-12, 'ence': 0.025056384899354616}]
var: {'subj. pred.': 1.0163788228274033e-23, 'subj. true.': 0.007725539, 'pred. err.': 0.041460142893771104}
Cv: {'subj. pred.': 0.9128061410569016, 'subj. true.': 2.099205399517044, 'pred. err.': 3.719199904127456}

Calibrated on prediction score:
GsbUME: [{'mae': 0.052548720943059915, 'ccc': 5.392914826626386e-12, 'ence': 0.015194085080670468}]
GpebUME: [{'mae': 0.1128476568501888, 'ccc': 8.022168590026318e-12, 'ence': 0.025056384899354616}]
var: {'subj. pred.': 1.0163788228274033e-23, 'subj. true.': 0.007725539, 'pred. err.': 0.041460142893771104}
Cv: {'subj. pred.': 0.9128061410569016, 'subj. true.': 2.099205399517044, 'pred. err.': 3.719199904127456}

/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:210: RuntimeWarning: divide by zero encountered in log
  regularization = (len(val_uncalibrated) / 2) * np.log(s)
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: divide by zero encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: invalid value encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
On Test: CCC  0.6063 | PCC  0.6208 | RMSE  0.1608
==================================================
On ground-truth labels:	Best	[Val CCC] for seed "314":	 0.4312
On ground-truth labels:		[Test CCC] for seed "314":	 0.6063
----------------------------------------------------------------------------------------------------
Delete model "/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/output/model/2021-06-12-09-02_[bert-4]_[valence]_[NOSEG]_[lstm_64_2_True]_[True_1_4]_[0.005_1024_0.5_0.5_0.5]_None_[1_314_None_None].pth".
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty_ensemble.py --feature_set vggish --emo_dim_set arousal --epochs 100 --refresh --n_seeds 5 --seed 314 --attn --rnn_bi --loss ccc --uncertainty_approach ensemble_averaging --attn_dr .5 --out_dr .5 --rnn_n_layers 2 --rnn_dr .5 --measure_uncertainty_globally --global_uncertainty_window 20 --normalize_uncalibrated_global_uncertainty_measurement
Constructing dataset and data loader ...
Constructing data from scratch ...
Calculating subjectivities among annotators from sratch...
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.6098, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.6961, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.6726, max 0.70778).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.853, max 0.9452999999999999).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.7745, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.39030000000000004, max 0.7343999999999999).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -1.0, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -1.0, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 9: 9
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 10: 10
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 11: 11
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 12: 12
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 13: 13
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 14: 14
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.39030000000000004, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 16: 16
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 17: 17
Subjectivities calculated.
Samples in partitions: (3122, 62, 64)
Input feature dim: 128.
==================================================
Training model... [seed 314]
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities.py:253: RuntimeWarning: invalid value encountered in double_scalars
  ccc = 2. * covariance / (x_var + y_var + (x_mean - y_mean) ** 2)
