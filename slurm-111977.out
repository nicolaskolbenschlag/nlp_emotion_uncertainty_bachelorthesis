/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty_ensemble.py --feature_set bert-4 --emo_dim_set valence --epochs 100 --refresh --n_seeds 5 --seed 314 --attn --rnn_bi --loss ccc --uncertainty_approach ensemble_averaging --attn_dr .5 --out_dr .5 --rnn_n_layers 2 --rnn_dr .5 --measure_uncertainty_globally --global_uncertainty_window 20 --normalize_uncalibrated_global_uncertainty_measurement --load_subjectivity_from_file
Constructing dataset and data loader ...
Constructing data from scratch ...
Subjectivities deserialized from file.
Samples in partitions: (3132, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 314 | Best [Val CCC]: 0.4312 [' 0.4312']| Loss: 0.6175 | PCC: 0.4429 ['0.4429'] | RMSE: 0.1844 ['0.1844']
On Test: CCC  0.5993 | PCC  0.6123 | RMSE  0.1657
==================================================
Training model... [seed 315]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 315 | Best [Val CCC]: 0.4431 [' 0.4431']| Loss: 0.6209 | PCC: 0.4516 ['0.4516'] | RMSE: 0.1921 ['0.1921']
On Test: CCC  0.6043 | PCC  0.6123 | RMSE  0.1572
==================================================
Training model... [seed 316]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 316 | Best [Val CCC]: 0.4489 [' 0.4489']| Loss: 0.5958 | PCC: 0.4500 ['0.4500'] | RMSE: 0.1740 ['0.1740']
On Test: CCC  0.5918 | PCC  0.6051 | RMSE  0.1567
==================================================
Training model... [seed 317]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 317 | Best [Val CCC]: 0.4549 [' 0.4549']| Loss: 0.6081 | PCC: 0.4552 ['0.4552'] | RMSE: 0.1705 ['0.1705']
On Test: CCC  0.5869 | PCC  0.5916 | RMSE  0.1664
==================================================
Training model... [seed 318]
Note: target can not be optimized for 15 consecutive epochs, early stop the training process!
Seed 318 | Best [Val CCC]: 0.4311 [' 0.4311']| Loss: 0.6124 | PCC: 0.4329 ['0.4329'] | RMSE: 0.1718 ['0.1718']
On Test: CCC  0.6114 | PCC  0.6155 | RMSE  0.1650
==================================================
--------------------TEST--------------------
Confirmed prediction ccc-score: 0.5464048520499647
Calibrator: isotonic_regression
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.3906945602366754, 'ccc': 0.08230650497793386, 'ence': 0.20507422390622987}], rand. GsbUME: [{'mae': 0.24179927508367152, 'ccc': 0.0031917494171640253, 'ence': 0.11804048429865087}]
GpebUME: [{'mae': 0.45905947838301947, 'ccc': 0.21480268490541513, 'ence': 0.18325537519355853}], rand. GpebUME: [{'mae': 0.2874041062815638, 'ccc': 0.01177327414365175, 'ence': 0.09178591707927063}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.5912491461295089, 'ccc': 0.04149559554724206, 'ence': 0.17515146414000302}]
var: {'subj. pred.': 0.1794707841053507, 'subj. true.': 0.047397375, 'pred. err.': 0.06865326717705741}
Cv: {'subj. pred.': -1.622093194221987, 'subj. true.': -0.43708278461388494, 'pred. err.': 3.4025631045446505}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06308363850837756, 'ccc': 0.030934631225376704, 'ence': 0.010631247077225353}]
GpebUME: [{'mae': 0.15442353385822474, 'ccc': 0.027770296354564263, 'ence': 0.06117663117440026}]
var: {'subj. pred.': 0.00012869862618638858, 'subj. true.': 0.0069582327, 'pred. err.': 0.06419404364919057}
Cv: {'subj. pred.': 0.2585632824000501, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5284859906734667}

Calibrated on prediction score:
GsbUME: [{'mae': 0.07544266462854991, 'ccc': 0.11053695098013447, 'ence': 0.09366554992040484}]
GpebUME: [{'mae': 0.14906807039716116, 'ccc': 0.16006304396873422, 'ence': 0.014422279811252886}]
var: {'subj. pred.': 0.004389501612339774, 'subj. true.': 0.0069582327, 'pred. err.': 0.06419404364919057}
Cv: {'subj. pred.': 0.8941039965313904, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5284859906734667}

Calibrator: std_scaling
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.3906945602366754, 'ccc': 0.08230650497793386, 'ence': 0.20507422390622987}], rand. GsbUME: [{'mae': 0.24189080179722597, 'ccc': 0.0012463239289108683, 'ence': 0.08791950372314611}]
GpebUME: [{'mae': 0.45905947838301947, 'ccc': 0.21480268490541513, 'ence': 0.18325537519355853}], rand. GpebUME: [{'mae': 0.2851473684504057, 'ccc': -0.024394337110244413, 'ence': 0.16465007687216368}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.5912491461295089, 'ccc': 0.04149559554724206, 'ence': 0.17515146414000302}]
var: {'subj. pred.': 0.1794707841053507, 'subj. true.': 0.047397375, 'pred. err.': 0.06865326717705741}
Cv: {'subj. pred.': -1.622093194221987, 'subj. true.': -0.43708278461388494, 'pred. err.': 3.4025631045446505}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06850805038247713, 'ccc': 5.388703262009907e-12, 'ence': 0.03241080312838398}]
GpebUME: [{'mae': 0.15831097557348922, 'ccc': 6.52903474725539e-12, 'ence': 0.050249856745949}]
var: {'subj. pred.': 7.437260707423423e-24, 'subj. true.': 0.0069582327, 'pred. err.': 0.06419404364919057}
Cv: {'subj. pred.': 0.7966619271995546, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5284859906734667}

Calibrated on prediction score:
GsbUME: [{'mae': 0.06850805038247713, 'ccc': 5.388703262009907e-12, 'ence': 0.03241080312838398}]
GpebUME: [{'mae': 0.15831097557348922, 'ccc': 6.52903474725539e-12, 'ence': 0.050249856745949}]
var: {'subj. pred.': 7.437260707423423e-24, 'subj. true.': 0.0069582327, 'pred. err.': 0.06419404364919057}
Cv: {'subj. pred.': 0.7966619271995546, 'subj. true.': 1.370725555775308, 'pred. err.': 2.5284859906734667}

--------------------DEVEL--------------------
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:210: RuntimeWarning: divide by zero encountered in log
  regularization = (len(val_uncalibrated) / 2) * np.log(s)
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: divide by zero encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: invalid value encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:210: RuntimeWarning: divide by zero encountered in log
  regularization = (len(val_uncalibrated) / 2) * np.log(s)
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: divide by zero encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities_global.py:211: RuntimeWarning: invalid value encountered in true_divide
  overconfidence = ((val_calibrated ** 2) / (2 * (s ** 2) * (val_uncalibrated ** 2))).sum()
Confirmed prediction ccc-score: 0.4219437780138436
Calibrator: isotonic_regression
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.37949690448417206, 'ccc': 0.04881273579637505, 'ence': 0.20567840318061945}], rand. GsbUME: [{'mae': 0.21233716215365392, 'ccc': -0.005639334559418879, 'ence': 0.07766288261398917}]
GpebUME: [{'mae': 0.4649126017335843, 'ccc': 0.12319419423636575, 'ence': 0.19011436197139284}], rand. GpebUME: [{'mae': 0.2354146337107019, 'ccc': -0.0026795277899507217, 'ence': 0.15579323365839148}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.6616414198807734, 'ccc': 0.02412760151443899, 'ence': 0.1982141295021914}]
var: {'subj. pred.': 0.1468639447641188, 'subj. true.': 0.039491754, 'pred. err.': 0.04931823313275906}
Cv: {'subj. pred.': -1.2585953085379744, 'subj. true.': -0.33696727768754087, 'pred. err.': 3.71229347511006}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.06097125116864307, 'ccc': 0.024473703343503555, 'ence': 8.651271879735187e-09}]
GpebUME: [{'mae': 0.12562050722737828, 'ccc': 0.021383878762611976, 'ence': 0.03005505201024317}]
var: {'subj. pred.': 9.570743627032374e-05, 'subj. true.': 0.007725539, 'pred. err.': 0.046994636378291085}
Cv: {'subj. pred.': 0.23364869267447957, 'subj. true.': 2.099205399517044, 'pred. err.': 3.539849567419639}

Calibrated on prediction score:
GsbUME: [{'mae': 0.07321610496687053, 'ccc': 0.07822599112607939, 'ence': 0.076625904023577}]
GpebUME: [{'mae': 0.1251893519838141, 'ccc': 0.12705573876881757, 'ence': 0.0}]
var: {'subj. pred.': 0.0031879956957665784, 'subj. true.': 0.007725539, 'pred. err.': 0.046994636378291085}
Cv: {'subj. pred.': 0.921975801681741, 'subj. true.': 2.099205399517044, 'pred. err.': 3.539849567419639}

Calibrator: std_scaling
Uncalibrated scores and benchmarking with random uncertainty quntification:
GsbUME: [{'mae': 0.37949690448417206, 'ccc': 0.04881273579637505, 'ence': 0.20567840318061945}], rand. GsbUME: [{'mae': 0.21207273792978754, 'ccc': 0.014828770731891778, 'ence': 0.08386067622717824}]
GpebUME: [{'mae': 0.4649126017335843, 'ccc': 0.12319419423636575, 'ence': 0.19011436197139284}], rand. GpebUME: [{'mae': 0.23513725975868172, 'ccc': -0.0170471421090296, 'ence': 0.1513613352074943}]
true-subjectivity-vs.-prediction-error: [{'mae': 0.6616414198807734, 'ccc': 0.02412760151443899, 'ence': 0.1982141295021914}]
var: {'subj. pred.': 0.1468639447641188, 'subj. true.': 0.039491754, 'pred. err.': 0.04931823313275906}
Cv: {'subj. pred.': -1.2585953085379744, 'subj. true.': -0.33696727768754087, 'pred. err.': 3.71229347511006}

Calibrated on true subjectivity:
GsbUME: [{'mae': 0.052548720943235566, 'ccc': 4.011942296455959e-12, 'ence': 0.016468645287695146}]
GpebUME: [{'mae': 0.12094681646820844, 'ccc': 5.12805155781768e-12, 'ence': 0.03662818174468364}]
var: {'subj. pred.': 6.356907587911451e-24, 'subj. true.': 0.007725539, 'pred. err.': 0.046994636378291085}
Cv: {'subj. pred.': 0.8803199317890611, 'subj. true.': 2.099205399517044, 'pred. err.': 3.539849567419639}

Calibrated on prediction score:
GsbUME: [{'mae': 0.052548720943235566, 'ccc': 4.011942296455959e-12, 'ence': 0.016468645287695146}]
GpebUME: [{'mae': 0.12094681646820844, 'ccc': 5.12805155781768e-12, 'ence': 0.03662818174468364}]
var: {'subj. pred.': 6.356907587911451e-24, 'subj. true.': 0.007725539, 'pred. err.': 0.046994636378291085}
Cv: {'subj. pred.': 0.8803199317890611, 'subj. true.': 2.099205399517044, 'pred. err.': 3.539849567419639}

On ground-truth labels:	Best	[Val CCC] for seed "317":	 0.4549
On ground-truth labels:		[Test CCC] for seed "317":	 0.5869
----------------------------------------------------------------------------------------------------
Delete model "/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/output/model/2021-06-10-21-27_[bert-4]_[valence]_[NOSEG]_[lstm_64_2_True]_[True_1_4]_[0.005_1024_0.5_0.5_0.5]_None_[5_317_None_None].pth".
/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty.py --feature_set bert-4 --emo_dim_set valence --epochs 100 --refresh --n_seeds 1 --seed 314 --attn --rnn_bi --loss ccc --uncertainty_approach monte_carlo_dropout --attn_dr .5 --out_dr .5 --rnn_n_layers 2 --rnn_dr .5 --measure_uncertainty_globally --global_uncertainty_window 20 --normalize_uncalibrated_global_uncertainty_measurement --load_subjectivity_from_file
Constructing dataset and data loader ...
Constructing data from scratch ...
Subjectivities deserialized from file.
Samples in partitions: (3132, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
