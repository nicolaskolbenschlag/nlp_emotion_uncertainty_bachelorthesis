MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty.py --feature_set bert-4 --emo_dim_set valence --epochs 1 --refresh --n_seeds 1 --seed 314 --predict --attn --rnn_bi --uncertainty_approach quantile_regression --loss tiltedCCC
Constructing dataset and data loader ...
Constructing data from scratch ...
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.6726, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -1.0, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.7353, max 0.80704).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.9549, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.9706, max 0.9218999999999999).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.39030000000000004, max 0.4687).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.98725, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.8137000000000001, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 9: 9
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 10: 10
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 11: 11
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 12: 12
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 13: 13
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 14: 14
Found cached annotator 2 video mapping.
Constructing data from scratch ...
No label preprocessing (min -0.58476, max 1.0).
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 16: 16
Found cached annotator 2 video mapping.
Constructing data from scratch ...
Exception for annotator 17: 17
Samples in partitions: (3132, 62, 64)
Input feature dim: 768.
==================================================
Training model... [seed 314]
rolling_correlation_error: torch.Size([1024, 198])
y_true: torch.Size([1024, 200])
rolling_correlation_error: torch.Size([1024, 191])
y_true: torch.Size([1024, 200])
rolling_correlation_error: torch.Size([1024, 198])
y_true: torch.Size([1024, 200])
rolling_correlation_error: torch.Size([1024, 191])
y_true: torch.Size([1024, 200])
rolling_correlation_error: torch.Size([1024, 198])
y_true: torch.Size([1024, 200])
rolling_correlation_error: torch.Size([1024, 191])
y_true: torch.Size([1024, 200])
rolling_correlation_error: torch.Size([60, 198])
y_true: torch.Size([60, 200])
rolling_correlation_error: torch.Size([60, 191])
y_true: torch.Size([60, 200])
rolling_correlation_error: torch.Size([1, 1542])
y_true: torch.Size([1, 1544])
rolling_correlation_error: torch.Size([1, 1535])
y_true: torch.Size([1, 1544])
rolling_correlation_error: torch.Size([1, 989])
y_true: torch.Size([1, 991])
rolling_correlation_error: torch.Size([1, 982])
y_true: torch.Size([1, 991])
rolling_correlation_error: torch.Size([1, 1572])
y_true: torch.Size([1, 1574])
rolling_correlation_error: torch.Size([1, 1565])
y_true: torch.Size([1, 1574])
rolling_correlation_error: torch.Size([1, 1354])
y_true: torch.Size([1, 1356])
rolling_correlation_error: torch.Size([1, 1347])
y_true: torch.Size([1, 1356])
rolling_correlation_error: torch.Size([1, 1066])
y_true: torch.Size([1, 1068])
rolling_correlation_error: torch.Size([1, 1059])
y_true: torch.Size([1, 1068])
rolling_correlation_error: torch.Size([1, 1540])
y_true: torch.Size([1, 1542])
rolling_correlation_error: torch.Size([1, 1533])
y_true: torch.Size([1, 1542])
rolling_correlation_error: torch.Size([1, 1266])
y_true: torch.Size([1, 1268])
rolling_correlation_error: torch.Size([1, 1259])
y_true: torch.Size([1, 1268])
rolling_correlation_error: torch.Size([1, 1601])
y_true: torch.Size([1, 1603])
rolling_correlation_error: torch.Size([1, 1594])
y_true: torch.Size([1, 1603])
rolling_correlation_error: torch.Size([1, 1354])
y_true: torch.Size([1, 1356])
rolling_correlation_error: torch.Size([1, 1347])
y_true: torch.Size([1, 1356])
rolling_correlation_error: torch.Size([1, 962])
y_true: torch.Size([1, 964])
rolling_correlation_error: torch.Size([1, 955])
y_true: torch.Size([1, 964])
rolling_correlation_error: torch.Size([1, 1435])
y_true: torch.Size([1, 1437])
rolling_correlation_error: torch.Size([1, 1428])
y_true: torch.Size([1, 1437])
rolling_correlation_error: torch.Size([1, 1519])
y_true: torch.Size([1, 1521])
rolling_correlation_error: torch.Size([1, 1512])
y_true: torch.Size([1, 1521])
rolling_correlation_error: torch.Size([1, 1230])
y_true: torch.Size([1, 1232])
rolling_correlation_error: torch.Size([1, 1223])
y_true: torch.Size([1, 1232])
rolling_correlation_error: torch.Size([1, 1467])
y_true: torch.Size([1, 1469])
rolling_correlation_error: torch.Size([1, 1460])
y_true: torch.Size([1, 1469])
rolling_correlation_error: torch.Size([1, 737])
y_true: torch.Size([1, 739])
rolling_correlation_error: torch.Size([1, 730])
y_true: torch.Size([1, 739])
rolling_correlation_error: torch.Size([1, 1529])
y_true: torch.Size([1, 1531])
rolling_correlation_error: torch.Size([1, 1522])
y_true: torch.Size([1, 1531])
rolling_correlation_error: torch.Size([1, 1097])
y_true: torch.Size([1, 1099])
rolling_correlation_error: torch.Size([1, 1090])
y_true: torch.Size([1, 1099])
rolling_correlation_error: torch.Size([1, 1270])
y_true: torch.Size([1, 1272])
rolling_correlation_error: torch.Size([1, 1263])
y_true: torch.Size([1, 1272])
rolling_correlation_error: torch.Size([1, 1050])
y_true: torch.Size([1, 1052])
rolling_correlation_error: torch.Size([1, 1043])
y_true: torch.Size([1, 1052])
rolling_correlation_error: torch.Size([1, 1229])
y_true: torch.Size([1, 1231])
rolling_correlation_error: torch.Size([1, 1222])
y_true: torch.Size([1, 1231])
rolling_correlation_error: torch.Size([1, 1514])
y_true: torch.Size([1, 1516])
rolling_correlation_error: torch.Size([1, 1507])
y_true: torch.Size([1, 1516])
rolling_correlation_error: torch.Size([1, 1298])
y_true: torch.Size([1, 1300])
rolling_correlation_error: torch.Size([1, 1291])
y_true: torch.Size([1, 1300])
rolling_correlation_error: torch.Size([1, 1076])
y_true: torch.Size([1, 1078])
rolling_correlation_error: torch.Size([1, 1069])
y_true: torch.Size([1, 1078])
rolling_correlation_error: torch.Size([1, 1191])
y_true: torch.Size([1, 1193])
rolling_correlation_error: torch.Size([1, 1184])
y_true: torch.Size([1, 1193])
rolling_correlation_error: torch.Size([1, 1073])
y_true: torch.Size([1, 1075])
rolling_correlation_error: torch.Size([1, 1066])
y_true: torch.Size([1, 1075])
rolling_correlation_error: torch.Size([1, 894])
y_true: torch.Size([1, 896])
rolling_correlation_error: torch.Size([1, 887])
y_true: torch.Size([1, 896])
rolling_correlation_error: torch.Size([1, 1601])
y_true: torch.Size([1, 1603])
rolling_correlation_error: torch.Size([1, 1594])
y_true: torch.Size([1, 1603])
rolling_correlation_error: torch.Size([1, 1665])
y_true: torch.Size([1, 1667])
rolling_correlation_error: torch.Size([1, 1658])
y_true: torch.Size([1, 1667])
rolling_correlation_error: torch.Size([1, 1480])
y_true: torch.Size([1, 1482])
rolling_correlation_error: torch.Size([1, 1473])
y_true: torch.Size([1, 1482])
rolling_correlation_error: torch.Size([1, 1124])
y_true: torch.Size([1, 1126])
rolling_correlation_error: torch.Size([1, 1117])
y_true: torch.Size([1, 1126])
rolling_correlation_error: torch.Size([1, 1225])
y_true: torch.Size([1, 1227])
rolling_correlation_error: torch.Size([1, 1218])
y_true: torch.Size([1, 1227])
rolling_correlation_error: torch.Size([1, 1024])
y_true: torch.Size([1, 1026])
rolling_correlation_error: torch.Size([1, 1017])
y_true: torch.Size([1, 1026])
rolling_correlation_error: torch.Size([1, 1075])
y_true: torch.Size([1, 1077])
rolling_correlation_error: torch.Size([1, 1068])
y_true: torch.Size([1, 1077])
rolling_correlation_error: torch.Size([1, 1097])
y_true: torch.Size([1, 1099])
rolling_correlation_error: torch.Size([1, 1090])
y_true: torch.Size([1, 1099])
rolling_correlation_error: torch.Size([1, 629])
y_true: torch.Size([1, 631])
rolling_correlation_error: torch.Size([1, 622])
y_true: torch.Size([1, 631])
rolling_correlation_error: torch.Size([1, 1453])
y_true: torch.Size([1, 1455])
rolling_correlation_error: torch.Size([1, 1446])
y_true: torch.Size([1, 1455])
rolling_correlation_error: torch.Size([1, 1307])
y_true: torch.Size([1, 1309])
rolling_correlation_error: torch.Size([1, 1300])
y_true: torch.Size([1, 1309])
rolling_correlation_error: torch.Size([1, 1093])
y_true: torch.Size([1, 1095])
rolling_correlation_error: torch.Size([1, 1086])
y_true: torch.Size([1, 1095])
rolling_correlation_error: torch.Size([1, 2011])
y_true: torch.Size([1, 2013])
rolling_correlation_error: torch.Size([1, 2004])
y_true: torch.Size([1, 2013])
rolling_correlation_error: torch.Size([1, 2810])
y_true: torch.Size([1, 2812])
rolling_correlation_error: torch.Size([1, 2803])
y_true: torch.Size([1, 2812])
rolling_correlation_error: torch.Size([1, 2376])
y_true: torch.Size([1, 2378])
rolling_correlation_error: torch.Size([1, 2369])
y_true: torch.Size([1, 2378])
rolling_correlation_error: torch.Size([1, 2236])
y_true: torch.Size([1, 2238])
rolling_correlation_error: torch.Size([1, 2229])
y_true: torch.Size([1, 2238])
rolling_correlation_error: torch.Size([1, 489])
y_true: torch.Size([1, 491])
rolling_correlation_error: torch.Size([1, 482])
y_true: torch.Size([1, 491])
rolling_correlation_error: torch.Size([1, 1611])
y_true: torch.Size([1, 1613])
rolling_correlation_error: torch.Size([1, 1604])
y_true: torch.Size([1, 1613])
rolling_correlation_error: torch.Size([1, 3800])
y_true: torch.Size([1, 3802])
rolling_correlation_error: torch.Size([1, 3793])
y_true: torch.Size([1, 3802])
rolling_correlation_error: torch.Size([1, 4088])
y_true: torch.Size([1, 4090])
rolling_correlation_error: torch.Size([1, 4081])
y_true: torch.Size([1, 4090])
rolling_correlation_error: torch.Size([1, 1608])
y_true: torch.Size([1, 1610])
rolling_correlation_error: torch.Size([1, 1601])
y_true: torch.Size([1, 1610])
rolling_correlation_error: torch.Size([1, 1791])
y_true: torch.Size([1, 1793])
rolling_correlation_error: torch.Size([1, 1784])
y_true: torch.Size([1, 1793])
rolling_correlation_error: torch.Size([1, 1335])
y_true: torch.Size([1, 1337])
rolling_correlation_error: torch.Size([1, 1328])
y_true: torch.Size([1, 1337])
rolling_correlation_error: torch.Size([1, 2231])
y_true: torch.Size([1, 2233])
rolling_correlation_error: torch.Size([1, 2224])
y_true: torch.Size([1, 2233])
rolling_correlation_error: torch.Size([1, 4970])
y_true: torch.Size([1, 4972])
rolling_correlation_error: torch.Size([1, 4963])
y_true: torch.Size([1, 4972])
rolling_correlation_error: torch.Size([1, 2198])
y_true: torch.Size([1, 2200])
rolling_correlation_error: torch.Size([1, 2191])
y_true: torch.Size([1, 2200])
rolling_correlation_error: torch.Size([1, 856])
y_true: torch.Size([1, 858])
rolling_correlation_error: torch.Size([1, 849])
y_true: torch.Size([1, 858])
rolling_correlation_error: torch.Size([1, 2603])
y_true: torch.Size([1, 2605])
rolling_correlation_error: torch.Size([1, 2596])
y_true: torch.Size([1, 2605])
rolling_correlation_error: torch.Size([1, 2481])
y_true: torch.Size([1, 2483])
rolling_correlation_error: torch.Size([1, 2474])
y_true: torch.Size([1, 2483])
rolling_correlation_error: torch.Size([1, 1210])
y_true: torch.Size([1, 1212])
rolling_correlation_error: torch.Size([1, 1203])
y_true: torch.Size([1, 1212])
rolling_correlation_error: torch.Size([1, 1870])
y_true: torch.Size([1, 1872])
rolling_correlation_error: torch.Size([1, 1863])
y_true: torch.Size([1, 1872])
rolling_correlation_error: torch.Size([1, 1966])
y_true: torch.Size([1, 1968])
rolling_correlation_error: torch.Size([1, 1959])
y_true: torch.Size([1, 1968])
rolling_correlation_error: torch.Size([1, 1185])
y_true: torch.Size([1, 1187])
rolling_correlation_error: torch.Size([1, 1178])
y_true: torch.Size([1, 1187])
rolling_correlation_error: torch.Size([1, 1907])
y_true: torch.Size([1, 1909])
rolling_correlation_error: torch.Size([1, 1900])
y_true: torch.Size([1, 1909])
rolling_correlation_error: torch.Size([1, 1897])
y_true: torch.Size([1, 1899])
rolling_correlation_error: torch.Size([1, 1890])
y_true: torch.Size([1, 1899])
rolling_correlation_error: torch.Size([1, 1057])
y_true: torch.Size([1, 1059])
rolling_correlation_error: torch.Size([1, 1050])
y_true: torch.Size([1, 1059])
Seed 314 | Best [Val CCC]: 0.0395 [' 0.0395']| Loss: 0.9450 | PCC: 0.1821 ['0.1821'] | RMSE: 0.2853 ['0.2853']
Traceback (most recent call last):
  File "MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty.py", line 332, in <module>
    main(params)
  File "MuSe-LSTM-Attention-baseline-model/emotion_recognition/main_uncertainty.py", line 213, in main
    sbUMEs, pebUMEs, Cvs, sbUMEs_cal, pebUMEs_cal, Cvs_cal = uncertainty_utilities.evaluate_uncertainty_measurement(model, data_loader["test"], params, data_loader["devel"])
  File "/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities.py", line 320, in evaluate_uncertainty_measurement
    full_means, full_vars, full_labels, full_subjectivities = prediction_fn(model, test_loader, params)
  File "/nas/student/NicolasKolbenschlag/emotion_uncertainty_bachelorarbeit/MuSe-LSTM-Attention-baseline-model/emotion_recognition/uncertainty_utilities.py", line 247, in outputs_quantile_regression
    assert vars_.shape == means.shape
AssertionError
slurmstepd: Exceeded step memory limit at some point.
slurmstepd: Exceeded job memory limit at some point.
